{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb6b91e-6ed8-4259-b9a6-4d48e4f78f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")         # 添加上级目录到路径，用于导入自定义模块\n",
    "from pinn import *            # 导入PINN基础模型\n",
    "from grad_stats import *      # 导入梯度统计计算模块\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, MultiStepLR\n",
    "from scipy.interpolate import griddata\n",
    "from pyDOE import lhs         # 拉丁超立方采样\n",
    "import scipy.io               # 用于加载.mat数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feebf610-0e25-4d92-bb6b-65334a190e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置设备（GPU或CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def sampler(num_r, num_b, num_0):\n",
    "    \"\"\"数据采样函数 - 生成训练所需的各类点\"\"\"\n",
    "\n",
    "    # 定义空间域的下界和上界\n",
    "    lb = np.array([-1.0])\n",
    "    ub = np.array([1.0])\n",
    "\n",
    "    # 加载Allen-Cahn方程的数据\n",
    "    data = scipy.io.loadmat('../data/AC.mat')\n",
    "\n",
    "    # 提取时间、空间坐标和精确解\n",
    "    t = data['tt'].flatten()[:,None] \n",
    "    x = data['x'].flatten()[:,None] \n",
    "    Exact = data['uu']\n",
    "    Exact_u = np.real(Exact)    # 取实部\n",
    "\n",
    "    #grab training points from domain\n",
    "    # 从初始条件中随机选择训练点\n",
    "    idx_x = np.random.choice(x.shape[0], num_0, replace=False)       #获得索引\n",
    "    x0 = x[idx_x,:]                                                  #取值\n",
    "    u0 = Exact_u[idx_x,0:1]     # t=0时刻的初始条件 \n",
    "\n",
    "    # 从时间域中随机选择边界点\n",
    "    idx_t = np.random.choice(t.shape[0], num_b, replace=False)       #获得索引\n",
    "    tb = t[idx_t,:]                                                  #取值\n",
    "    \n",
    "    # Grab collocation points using latin hpyercube sampling\n",
    "    # 使用拉丁超立方采样选择配点（用于PDE残差计算）\n",
    "    X_f = lb + (ub-lb)*lhs(2, num_r)\n",
    "    X_f[:,1:2] = np.abs(X_f[:,1:2])    # 确保时间为正\n",
    "\n",
    "    # 构建各类训练点集（位置、时间数据拼接）\n",
    "    X0 = np.concatenate((x0, np.abs(0*x0)), 1) # 初始条件点(x0, 0) \n",
    "    X_lb = np.concatenate((0*tb + lb[0], tb), 1) # 左边界点(lb[0], tb)  \n",
    "    X_ub = np.concatenate((0*tb + ub[0], tb), 1) # 右边界点(ub[0], tb) \n",
    "    \n",
    "    \n",
    "    #generate meshgrid\n",
    "    # 生成用于验证的网格点\n",
    "    X, T = np.meshgrid(x,t)      #将位置x时间t组合成二维网格\n",
    "    \n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))  #将空间时间对压缩成一维数组\n",
    "    u_sol = Exact_u.T.flatten()[:,None]    #转置后与网格对齐，并展平为一维数组，对应X_star\n",
    "\n",
    "    # 计算输入数据的均值和标准差（用于数据标准化）\n",
    "    X_mean = torch.tensor(np.mean(np.concatenate([X_f, X_lb, X_ub, X0], 0), axis=0, keepdims=True), dtype=torch.float32, device=device)\n",
    "    \n",
    "    X_std  = torch.tensor(np.std(np.concatenate([X_f, X_lb, X_ub, X0], 0), axis=0, keepdims=True), dtype=torch.float32, device=device)\n",
    "\n",
    "    # 将数据转换为PyTorch张量\n",
    "    X_train = torch.tensor(X_f, dtype=torch.float32, requires_grad=True,device=device)  # 配点，需要梯度\n",
    "    \n",
    "    X_lb = torch.tensor(X_lb, dtype=torch.float32, device=device, requires_grad=True)   # 左边界点\n",
    "    X_rb = torch.tensor(X_ub, dtype=torch.float32, device=device, requires_grad=True)   # 右边界点\n",
    "    \n",
    "    X_ic = torch.tensor(X0, dtype=torch.float32, device=device)    # 初始条件点\n",
    "    \n",
    "    # compute mean and std of training data\n",
    "    U_ic = torch.tensor(u0, dtype=torch.float32, device=device)    # 初始条件值\n",
    "    \n",
    "    return X_train, X_lb, X_rb, X_ic, U_ic, X_mean, X_std, X, T, Exact_u, X_star, u_sol\n",
    "\n",
    "\n",
    "\n",
    "###### computes pde residual\n",
    "def AC_res(uhat, data): \n",
    "    \"\"\"计算Allen-Cahn方程的PDE残差\"\"\"\n",
    "    x = data[:,0:1]      # 空间坐标\n",
    "    t = data[:,1:2]      # 时间坐标\n",
    "\n",
    "    # 计算一阶导数\n",
    "    du = grad(outputs=uhat, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    \n",
    "    dudx = du[:,0:1]     # 对x的一阶偏导\n",
    "    dudt = du[:,1:2]     # 对t的一阶偏导\n",
    "\n",
    "    # 计算二阶导数（对x的二阶偏导）\n",
    "    dudxx = grad(outputs=dudx, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0][:,0:1]\n",
    "\n",
    "    # Allen-Cahn方程残差: u_t - ε*u_xx + f(u) = 0\n",
    "    # 这里 ε=0.0001, f(u)=5u^3-5u\n",
    "    residual = dudt - 0.0001*dudxx + 5*uhat**3 - 5*uhat\n",
    "    \n",
    "    return residual\n",
    "\n",
    "\n",
    "def AC_res_u_x(uhat, data): #data=(x,t)\n",
    "    \"\"\"计算解对x的一阶偏导（用于周期性边界条件）\"\"\"\n",
    "    du = grad(outputs=uhat, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    \n",
    "    dudx = du[:,0:1]    # 对x的一阶偏导\n",
    "    return dudx     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f7be698-7ad2-4fb3-81df-697ef566a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guding_lr, lr:  True 0.001\n",
      "num_r, num_b, num_0:  20000 100 512\n",
      "layer_sizes:  [2, 128, 128, 128, 128, 1]\n"
     ]
    }
   ],
   "source": [
    "# 训练参数设置\n",
    "i_print = 100       # 打印间隔\n",
    "all_losses=[]       # 存储所有损失\n",
    "list_of_l2_Errors=[]   # 存储L2误差\n",
    "\n",
    "lr = 1e-3           # 学习率\n",
    "mm         = 100    # 权重更新频率\n",
    "alpha_ann  = 0.1    # 传统方法的权重更新系数\n",
    "n_epochs   = 300  # 总训练轮数\n",
    "\n",
    "layer_sizes =  [2, 128, 128, 128, 128, 1]    # 网络结构 [输入, 隐藏层..., 输出]\n",
    "num_0 = 512        # 初始条件点数\n",
    "num_b = 100   #actually N_b is 200 for lb and ub    # 单边边界条件点数（实际总边界点数为2*num_b）\n",
    "num_r = 20000      # 配点数\n",
    "\n",
    "# 学习率调度策略\n",
    "guding_lr = True\n",
    "if guding_lr:\n",
    "    path_loc= './results/guding_lr_%s_rb0_%s_%s_%s_iter_%s_%s' % (lr, num_r, num_b, num_0, n_epochs, layer_sizes) \n",
    "else:\n",
    "    path_loc= './results/step_lr_%s_rb0_%s_%s_%s_iter_%s_%s' % (lr, num_r, num_b, num_0, n_epochs, layer_sizes) \n",
    "\n",
    "# 创建结果保存目录\n",
    "print('guding_lr, lr: ', guding_lr, lr)\n",
    "print('num_r, num_b, num_0: ', num_r, num_b, num_0)\n",
    "print('layer_sizes: ', layer_sizes)\n",
    "\n",
    "if not os.path.exists(path_loc):\n",
    "    os.makedirs(path_loc)\n",
    "\n",
    "\n",
    "# 定义要比较的方法列表\n",
    "# 0: 等权重PINN; 1: GW-PINN (mean); 2: GW-PINN (std); 3: GW-PINN (kurtosis)\n",
    "# DB_PINN_mean/std/kurt: DB-PINN的三种变体\n",
    "method_list = [0, 1, 2, 3, 'DB_PINN_mean', 'DB_PINN_std', 'DB_PINN_kurt']\n",
    "#0: vanilla PINN (Equal Weighting); GW-PINN: 1: mean (max/avg); 2: std; 3: kurtosis;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99451876-d712-4a31-b5c1-86360fe55900",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.time())\n",
    "# 主训练循环\n",
    "for i in range(7):   # 遍历7种方法\n",
    "    method = method_list[i]\n",
    "    for j in range(1):   # 每种方法运行1次（可扩展为多次取平均）\n",
    "        \n",
    "        print('i, j, method: ', i, j, method)\n",
    "        save_loc = path_loc + '/method_' + str(method) + '/run_' + str(j) \n",
    "        if not os.path.exists(save_loc):\n",
    "            os.makedirs(save_loc)\n",
    "        \n",
    "        extras=str(num_r)+ \"+\"+ str(num_b) + \"+\" + str(num_0)\n",
    "        print(\"#######Training with#####\\n\",extras)\n",
    "\n",
    "        # 采样训练数据\n",
    "        X_train, X_lb, X_rb, X_ic, U_ic, X_mean, X_std, X, T, Exact_u, X_star, u_sol = sampler(num_r, num_b, num_0)\n",
    "        \n",
    "        # 初始化PINN网络\n",
    "        net = PINN(sizes=layer_sizes, mean=X_mean, std=X_std, activation=torch.nn.Tanh()).to(device)\n",
    "\n",
    "        # 初始化损失权重（DB-PINN论文中的λ^i）\n",
    "        lambd_r       = torch.ones(1, device=device)\n",
    "        lambd_bc       = torch.ones(1, device=device)\n",
    "        lambd_ic       = torch.ones(1, device=device) \n",
    "\n",
    "        # 记录权重历史\n",
    "        lambd_r_all       = [];\n",
    "        lambd_bc_all      = [];\n",
    "        lambd_ic_all      = [];\n",
    "\n",
    "        # 记录损失和误差历史\n",
    "        losses = []\n",
    "        losses_initial  = [];\n",
    "        losses_boundary  = [];\n",
    "        losses_residual = [];\n",
    "        l2_error = []\n",
    "        \n",
    "        N_l = 0          # 权重更新计数器（用于DB-PINN的在线平均计算）\n",
    "        \n",
    "        # 优化器设置\n",
    "        params = [{'params': net.parameters(), 'lr': lr}]  \n",
    "        milestones = [[20000,40000,60000]]       # 学习率调整的里程碑\n",
    "        \n",
    "        if guding_lr:\n",
    "            optimizer = Adam(params)    # 固定学习率\n",
    "        else:\n",
    "            optimizer = Adam(params) \n",
    "            scheduler = MultiStepLR(optimizer, milestones[0], gamma=0.95)     # 多步学习率衰减\n",
    "        \n",
    "        print(\"training with shape of residual points: \", X_train.size())\n",
    "        print(\"training with shape of boundary points (*2): \", X_lb.size())\n",
    "        print(\"training with shape of initial points: \", X_ic.size())\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "         # 训练循环\n",
    "        for epoch in range(n_epochs): \n",
    "\n",
    "            # 前向传播：计算各损失项\n",
    "            uhat  = net(X_train)  # 在配点处的预测\n",
    "            res   = AC_res(uhat, X_train)   # PDE残差\n",
    "            l_reg = torch.mean((res)**2)    # PDE残差损失\n",
    "\n",
    "            # 边界条件计算\n",
    "            predl = net(X_lb)     # 左边界预测\n",
    "            predr = net(X_rb)     # 右边界预测\n",
    "            \n",
    "            predl_dx = AC_res_u_x(predl, X_lb)         # 左边界一阶导\n",
    "            predr_dx = AC_res_u_x(predr, X_rb)         # 右边界一阶导\n",
    "\n",
    "            # 周期性边界条件损失：函数值和一阶导都匹配\n",
    "            l_bc  = torch.mean((predl - predr)**2)  \n",
    "            l_bc += torch.mean((predl_dx - predr_dx)**2)\n",
    "\n",
    "            # 初始条件损失\n",
    "            pred_ic = net(X_ic)\n",
    "            l_ic = torch.mean((pred_ic - U_ic)**2)\n",
    "\n",
    "            # 组合所有条件损失（用于DB-PINN的难度指数计算）\n",
    "            L_t = torch.stack((l_reg, l_bc, l_ic))\n",
    "            \n",
    "            # 权重更新部分（每mm个epoch更新一次）\n",
    "            with torch.no_grad():\n",
    "                if epoch % mm == 0:\n",
    "                    N_l += 1    # 更新计数器\n",
    "\n",
    "                    # 计算各损失的梯度统计量（用于权重计算）\n",
    "                    stdr,kurtr=loss_grad_stats(l_reg, net)        # PDE残差的梯度的标准差和峰度\n",
    "                    stdb,kurtb=loss_grad_stats(l_bc, net)         # 边界条件的梯度统计\n",
    "                    stdi,kurti=loss_grad_stats(l_ic, net)         # 初始条件的梯度统计\n",
    "                    \n",
    "                    maxr,meanr=loss_grad_max_mean(l_reg, net)     # PDE残差的梯度最大值和均值\n",
    "                    maxb,meanb=loss_grad_max_mean(l_bc, net,lambg=lambd_bc)     # 边界条件的梯度统计\n",
    "                    maxi,meani=loss_grad_max_mean(l_ic, net,lambg=lambd_ic)     # 初始条件的梯度统计\n",
    "\n",
    "                    # 初始化DB-PINN的在线平均变量\n",
    "                    if epoch == 0:\n",
    "                        lam_avg_bc = torch.zeros(1, device=device)         # 边界权重的运行平均\n",
    "                        lam_avg_ic = torch.zeros(1, device=device)         # 初始权重的运行平均\n",
    "                        running_mean_L = torch.zeros(1, device=device)     # 损失向量的运行平均\n",
    "\n",
    "                    # 方法1: GW-PINN (mean) - 基于梯度均值比\n",
    "                    if method == 1:\n",
    "                        # max/avg    # max/avg 方法：PDE梯度最大值 / 条件梯度均值\n",
    "                        lamb_hat = maxr/meanb\n",
    "                        lambd_bc     = (1-alpha_ann)*lambd_bc + alpha_ann*lamb_hat    # EMA更新\n",
    "                        lamb_hat = maxr/meani\n",
    "                        lambd_ic     = (1-alpha_ann)*lambd_ic + alpha_ann*lamb_hat \n",
    "\n",
    "                    # 方法2: GW-PINN (std) - 基于梯度标准差比（逆Dirichlet加权）\n",
    "                    elif method == 2:\n",
    "                        # inverse dirichlet\n",
    "                        lamb_hat = stdr/stdb\n",
    "                        lambd_bc     = (1-alpha_ann)*lambd_bc + alpha_ann*lamb_hat\n",
    "                        lamb_hat = stdr/stdi\n",
    "                        lambd_ic     = (1-alpha_ann)*lambd_ic + alpha_ann*lamb_hat\n",
    "\n",
    "                    # 方法3: GW-PINN (kurtosis) - 基于梯度峰度比\n",
    "                    elif method == 3:\n",
    "                        # kurtosis based weighing    \n",
    "                        covr= stdr/kurtr     # 标准差/峰度\n",
    "                        covb= stdb/kurtb\n",
    "                        covi= stdi/kurti\n",
    "                        lamb_hat = covr/covb\n",
    "                        lambd_bc     = (1-alpha_ann)*lambd_bc + alpha_ann*lamb_hat\n",
    "                        lamb_hat = covr/covi\n",
    "                        lambd_ic     = (1-alpha_ann)*lambd_ic + alpha_ann*lamb_hat\n",
    "\n",
    "                    # DB-PINN (mean变体) - 结合inter-balancing和intra-balancing\n",
    "                    elif method == 'DB_PINN_mean':\n",
    "                        # Inter-balancing: 计算总梯度比率G（公式4）\n",
    "                        hat_all = maxr/meanb + maxr/meani\n",
    "\n",
    "                        # Intra-balancing: 使用Welford算法更新损失均值（公式7）\n",
    "                        mean_param = (1. - 1 / N_l)\n",
    "                        running_mean_L = mean_param * running_mean_L + (1 - mean_param) * L_t.detach()\n",
    "\n",
    "                        # 计算难度指数（公式5）：当前损失/历史平均损失\n",
    "                        l_t_vector = L_t/running_mean_L\n",
    "\n",
    "                        # 权重分配（公式6）：按难度指数比例分配聚合权重\n",
    "                        hat_bc = hat_all* l_t_vector[1]/(l_t_vector[1] + l_t_vector[2])\n",
    "                        hat_ic = hat_all* l_t_vector[2]/(l_t_vector[1] + l_t_vector[2])\n",
    "                        lambd_bc = lam_avg_bc + 1/N_l*(hat_bc - lam_avg_bc)\n",
    "                        lambd_ic = lam_avg_ic + 1/N_l*(hat_ic - lam_avg_ic)\n",
    "                        lam_avg_bc = lambd_bc\n",
    "                        lam_avg_ic = lambd_ic\n",
    "\n",
    "                    # DB-PINN (std变体)\n",
    "                    elif method == 'DB_PINN_std':  \n",
    "                        hat_all = stdr/stdb + stdr/stdi         # 使用标准差统计量\n",
    "                        \n",
    "                        mean_param = (1. - 1 / N_l)\n",
    "                        running_mean_L = mean_param * running_mean_L + (1 - mean_param) * L_t.detach()\n",
    "                        l_t_vector = L_t/running_mean_L\n",
    "                        hat_bc = hat_all* l_t_vector[1]/(l_t_vector[1] + l_t_vector[2])\n",
    "                        hat_ic = hat_all* l_t_vector[2]/(l_t_vector[1] + l_t_vector[2])\n",
    "                        lambd_bc = lam_avg_bc + 1/N_l*(hat_bc - lam_avg_bc)\n",
    "                        lambd_ic = lam_avg_ic + 1/N_l*(hat_ic - lam_avg_ic)\n",
    "                        lam_avg_bc = lambd_bc\n",
    "                        lam_avg_ic = lambd_ic\n",
    "\n",
    "                    # DB-PINN (kurtosis变体)\n",
    "                    elif method == 'DB_PINN_kurt':  \n",
    "                        covr= stdr/kurtr\n",
    "                        covb= stdb/kurtb\n",
    "                        covi= stdi/kurti\n",
    "                        hat_all = covr/covb + covr/covi          # 使用峰度统计量\n",
    "                        \n",
    "                        mean_param = (1. - 1 / N_l)\n",
    "                        running_mean_L = mean_param * running_mean_L + (1 - mean_param) * L_t.detach()\n",
    "                        l_t_vector = L_t/running_mean_L\n",
    "                        hat_bc = hat_all* l_t_vector[1]/(l_t_vector[1] + l_t_vector[2])\n",
    "                        hat_ic = hat_all* l_t_vector[2]/(l_t_vector[1] + l_t_vector[2])\n",
    "                        lambd_bc = lam_avg_bc + 1/N_l*(hat_bc - lam_avg_bc)\n",
    "                        lambd_ic = lam_avg_ic + 1/N_l*(hat_ic - lam_avg_ic)\n",
    "                        lam_avg_bc = lambd_bc\n",
    "                        lam_avg_ic = lambd_ic\n",
    "                            \n",
    "                    else:\n",
    "                        # equal weighting       # 方法0: 等权重PINN（基线方法）\n",
    "                        lambd_bc = torch.ones(1, device=device)\n",
    "                        lambd_ic = torch.ones(1, device=device)\n",
    "\n",
    "            # 计算加权总损失（DB-PINN论文中的公式2）\n",
    "            loss = l_reg + lambd_bc.item()*l_bc + lambd_ic.item()*l_ic\n",
    "\n",
    "            # 定期输出训练信息\n",
    "            if epoch%i_print==0:\n",
    "\n",
    "                # 计算验证集上的L2相对误差\n",
    "                inp = torch.tensor(X_star, dtype=torch.float32, device=device, requires_grad=True)\n",
    "                out = net(inp).cpu().data.numpy().reshape(u_sol.shape)\n",
    "                tmp = np.linalg.norm(out.reshape(-1)-u_sol.reshape(-1))/np.linalg.norm(out.reshape(-1))\n",
    "\n",
    "                 # 记录各种指标\n",
    "                l2_error.append(tmp)\n",
    "                list_of_l2_Errors.append(tmp)\n",
    "                all_losses.append(loss.item())\n",
    "                \n",
    "                losses_initial.append(l_ic.item())\n",
    "                losses_boundary.append(l_bc.item())\n",
    "                losses_residual.append(l_reg.item())\n",
    "               \n",
    "                lambd_r_all.append(lambd_r.item())\n",
    "                lambd_bc_all.append(lambd_bc.item())\n",
    "                lambd_ic_all.append(lambd_ic.item())\n",
    "\n",
    "                # 打印训练状态\n",
    "                print(\"method={}, epoch {}/{}, loss={:.4f}, loss_r={:.6f}, loss_bc={:.6f}, loss_ic={:.6f}, lam_r={:.4f}, lam_bc={:.4f}, lam_ic={:.4f}, lr={:.5f}, l2_error(%)={:.3f}\".format(method, epoch+1, n_epochs, loss.item(), l_reg.item(), l_bc.item(), l_ic.item(), lambd_r.item(), lambd_bc.item(), lambd_ic.item(), optimizer.param_groups[0]['lr'], tmp*100)) \n",
    "            \n",
    "            # 反向传播和参数更新\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if guding_lr:\n",
    "                optimizer.step()      # 固定学习率\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                scheduler.step()      # 学习率调度\n",
    "\n",
    "        # 训练结束，计算最终性能\n",
    "        elapsed_time = time.time() - start_time\n",
    "        inp = torch.tensor(X_star, dtype=torch.float32, device=device, requires_grad=True )\n",
    "        out = net(inp)\n",
    "        out = out.cpu().data.numpy().reshape(u_sol.shape)\n",
    "\n",
    "        print(\"\\n.....\\n\")\n",
    "        print(\"Method: , j: \",method, j)\n",
    "        print(\"pred rel. l2-error = {:e}\\n\".format(np.linalg.norm(out.reshape(-1)-u_sol.reshape(-1))/np.linalg.norm(u_sol.reshape(-1))))\n",
    "        print(\"pred abs. error = {:e}\\n\".format(np.mean(np.abs(out.reshape(-1)-u_sol.reshape(-1)))))\n",
    "        print(\"\\n.....\\n\")\n",
    "        \n",
    "        # 插值得到网格上的预测结果\n",
    "        U_pred = griddata(X_star, out.flatten(), (X, T), method='cubic')\n",
    "        \n",
    "        ############plot results\n",
    "        fig = plt.figure(1, figsize=(18, 5))\n",
    "        fig_1 = plt.subplot(1, 3, 1)\n",
    "        plt.pcolor(X, T, Exact_u.T, cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(r'$x$')\n",
    "        plt.ylabel(r'$t$')\n",
    "        plt.title('Exact $u(x)$')\n",
    "        fig_2 = plt.subplot(1, 3, 2)\n",
    "        plt.pcolor(X, T, U_pred, cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(r'$x$')\n",
    "        plt.ylabel(r'$t$')\n",
    "        plt.title('Predicted $u(x)$')\n",
    "        fig_3 = plt.subplot(1, 3, 3)\n",
    "        plt.pcolor(X, T, np.abs(Exact_u.T - U_pred), cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(r'$x$')\n",
    "        plt.ylabel(r'$t$')\n",
    "        plt.title('Absolute error')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_loc,'1.predictions.png'))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        fig_2 = plt.figure(2)\n",
    "        ax = fig_2.add_subplot(1, 1, 1)\n",
    "        ax.plot(losses_residual, label='$\\mathcal{L}_{r}$')\n",
    "        ax.plot(losses_boundary, label='$\\mathcal{L}_{bc}$')\n",
    "        ax.plot(losses_initial, label='$\\mathcal{L}_{ic}$')        \n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlabel('iterations')\n",
    "        ax.set_ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_loc, '2.loss.png'))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        fig_3 = plt.figure(3)\n",
    "        ax = fig_3.add_subplot(1, 1, 1)\n",
    "        ax.plot(lambd_bc_all, label='$\\lambda_{bc}$')\n",
    "        ax.plot(lambd_ic_all, label='$\\lambda_{ic}$')\n",
    "        ax.set_xlabel('iterations')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_loc,'3.learned_weights.png'))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        fig_4 = plt.figure(4)\n",
    "        ax = fig_4.add_subplot(1, 1, 1)\n",
    "        ax.plot(l2_error)\n",
    "        ax.set_xlabel('iterations')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_loc,'4.L2_error.png'))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3dcea-e12e-45af-9294-8f0fe846a2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66eade5-1ab5-45c9-b37f-b6dac17d92cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PP",
   "language": "python",
   "name": "pp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
